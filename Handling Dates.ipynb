{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1418eea8-a0b0-462c-9082-3751ec6f44e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:31:53.170199Z",
     "iopub.status.busy": "2025-12-23T20:31:53.169915Z",
     "iopub.status.idle": "2025-12-23T20:31:54.135706Z",
     "shell.execute_reply": "2025-12-23T20:31:54.135017Z",
     "shell.execute_reply.started": "2025-12-23T20:31:53.170171Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/23 20:31:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    ".appName('Handle Date Type')\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d8020f-1cf8-4dd5-857c-3e17c9592c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:31:58.220134Z",
     "iopub.status.busy": "2025-12-23T20:31:58.219893Z",
     "iopub.status.idle": "2025-12-23T20:31:58.224401Z",
     "shell.execute_reply": "2025-12-23T20:31:58.223460Z",
     "shell.execute_reply.started": "2025-12-23T20:31:58.220111Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sending the Data to HDFS Via Notebook\n",
    "\n",
    "# Create a CSV file\n",
    "csv_data = \"\"\"id,date_iso,date_dmy,date_mdy,timestamp\n",
    "1,2023-01-15,15/01/2023,01/15/2023,2023-01-15 10:30:00\n",
    "2,2023-05-20,20/05/2023,05/20/2023,2023-05-20 15:45:00\n",
    "3,InvalidDate,31/02/2023,02/31/2023,InvalidTimestamp\n",
    "4,,,, \n",
    "\"\"\"\n",
    "\n",
    "# Save the CSV file\n",
    "with open(\"dates_data.csv\", \"w\") as f:\n",
    "    f.write(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f253ead0-1ef1-4d61-82f1-f04d1e24703e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:31:54.146045Z",
     "iopub.status.busy": "2025-12-23T20:31:54.145832Z",
     "iopub.status.idle": "2025-12-23T20:31:54.325144Z",
     "shell.execute_reply": "2025-12-23T20:31:54.324562Z",
     "shell.execute_reply.started": "2025-12-23T20:31:54.146022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates_data.csv\n"
     ]
    }
   ],
   "source": [
    "!ls *dates_data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb11fbf7-2838-4a77-93dd-bce4efa09a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:32:00.925450Z",
     "iopub.status.busy": "2025-12-23T20:32:00.925207Z",
     "iopub.status.idle": "2025-12-23T20:32:04.570757Z",
     "shell.execute_reply": "2025-12-23T20:32:04.570007Z",
     "shell.execute_reply.started": "2025-12-23T20:32:00.925431Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `/data/dates_data.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put dates_data.csv /data/dates_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e33154e-2d78-4680-98c5-342ec018680f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:32:04.572047Z",
     "iopub.status.busy": "2025-12-23T20:32:04.571846Z",
     "iopub.status.idle": "2025-12-23T20:32:08.151645Z",
     "shell.execute_reply": "2025-12-23T20:32:08.150880Z",
     "shell.execute_reply.started": "2025-12-23T20:32:04.572021Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   2 root hadoop       5488 2025-12-20 19:02 /data/customers_100.csv\n",
      "-rw-r--r--   2 root hadoop        210 2025-12-22 13:34 /data/dates_data.csv\n",
      "drwxr-xr-x   - root hadoop          0 2025-12-20 20:26 /data/write_output.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8478a7e-b294-4696-91a0-d96b47ffcd6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# # StructType for the schema\n",
    "# struct_schema = StructType([\n",
    "#     StructField(\"id\", IntegerType(), nullable=True),\n",
    "#     StructField(\"date_iso\", StringType(), nullable=True),\n",
    "#     StructField(\"date_dmy\", StringType(), nullable=True),\n",
    "#     StructField(\"date_mdy\", StringType(), nullable=True),\n",
    "#     StructField(\"timestamp\", StringType(), nullable=True)\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "682c0d54-3b7f-4c18-81ed-9462adf90579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:32:08.154880Z",
     "iopub.status.busy": "2025-12-23T20:32:08.154629Z",
     "iopub.status.idle": "2025-12-23T20:32:15.119933Z",
     "shell.execute_reply": "2025-12-23T20:32:15.119170Z",
     "shell.execute_reply.started": "2025-12-23T20:32:08.154857Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+----------+-------------------+\n",
      "|id |date_iso   |date_dmy  |date_mdy  |timestamp          |\n",
      "+---+-----------+----------+----------+-------------------+\n",
      "|1  |2023-01-15 |15/01/2023|01/15/2023|2023-01-15 10:30:00|\n",
      "|2  |2023-05-20 |20/05/2023|05/20/2023|2023-05-20 15:45:00|\n",
      "|3  |InvalidDate|31/02/2023|02/31/2023|InvalidTimestamp   |\n",
      "|4  |NULL       |NULL      |NULL      |                   |\n",
      "+---+-----------+----------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema\n",
    "ddl_schema = \"\"\"\n",
    "    id INT,\n",
    "    date_iso STRING,\n",
    "    date_dmy STRING,\n",
    "    date_mdy STRING,\n",
    "    timestamp STRING\n",
    "\"\"\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_file = spark.read.option(\"header\", True).schema(ddl_schema).csv(\"/data/dates_data.csv\")\n",
    "\n",
    "# Show the DataFrame\n",
    "df_file.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc14ff-9c4c-4b9b-89b2-6a9ef0d31002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f567f-3918-4fc2-b4c0-e01c546c2fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4cbd7-25db-4b9b-9d8c-6b82747337c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e879316-e4f8-45af-b28c-73578cb7ad65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef91029-0d84-46c6-9387-21c65434fbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e990585-a312-4d6f-9cc4-627ac4ef3a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:32:17.582721Z",
     "iopub.status.busy": "2025-12-23T20:32:17.582471Z",
     "iopub.status.idle": "2025-12-23T20:32:21.288614Z",
     "shell.execute_reply": "2025-12-23T20:32:21.287948Z",
     "shell.execute_reply.started": "2025-12-23T20:32:17.582703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+----------+-------------------+\n",
      "|id |date_iso   |date_dmy  |date_mdy  |timestamp          |\n",
      "+---+-----------+----------+----------+-------------------+\n",
      "|1  |2023-01-15 |15/01/2023|01/15/2023|2023-01-15 10:30:00|\n",
      "|2  |2023-05-20 |20/05/2023|05/20/2023|2023-05-20 15:45:00|\n",
      "|3  |InvalidDate|31/02/2023|02/31/2023|InvalidTimestamp   |\n",
      "|4  |NULL       |NULL      |NULL      |NULL               |\n",
      "+---+-----------+----------+----------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sample data with multiple date formats\n",
    "data = [\n",
    "    (1, \"2023-01-15\", \"15/01/2023\", \"01/15/2023\", \"2023-01-15 10:30:00\"),\n",
    "    (2, \"2023-05-20\", \"20/05/2023\", \"05/20/2023\", \"2023-05-20 15:45:00\"),\n",
    "    (3, \"InvalidDate\", \"31/02/2023\", \"02/31/2023\", \"InvalidTimestamp\"),  # Invalid dates\n",
    "    (4, None, None, None, None)  # Null values\n",
    "]\n",
    "\n",
    "# Define column names\n",
    "columns = [\"id\", \"date_iso\", \"date_dmy\", \"date_mdy\", \"timestamp\"]\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(data, schema = columns)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8582efe9-85c1-4d76-b0bf-71e2d149d045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:32:26.285430Z",
     "iopub.status.busy": "2025-12-23T20:32:26.285202Z",
     "iopub.status.idle": "2025-12-23T20:32:26.291016Z",
     "shell.execute_reply": "2025-12-23T20:32:26.290327Z",
     "shell.execute_reply.started": "2025-12-23T20:32:26.285413Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- date_iso: string (nullable = true)\n",
      " |-- date_dmy: string (nullable = true)\n",
      " |-- date_mdy: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75be711e-ce96-4492-a4fb-feab75dcdab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:38:15.403053Z",
     "iopub.status.busy": "2025-12-23T20:38:15.402805Z",
     "iopub.status.idle": "2025-12-23T20:38:15.491827Z",
     "shell.execute_reply": "2025-12-23T20:38:15.490829Z",
     "shell.execute_reply.started": "2025-12-23T20:38:15.403035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "df = df\\\n",
    "        .withColumn('parsed_date_iso',to_date(df.date_iso,'yyyy-MM-dd'))\\\n",
    "        .withColumn('parsed_date_dmy',to_date(df.date_dmy,'dd/MM/yyyy'))\\\n",
    "        .withColumn('parsed_date_mdy',to_date(df.date_mdy,'MM/dd/yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f51bae5-7cd6-4c9b-82d9-b0220f578524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:38:27.697118Z",
     "iopub.status.busy": "2025-12-23T20:38:27.696870Z",
     "iopub.status.idle": "2025-12-23T20:38:28.738299Z",
     "shell.execute_reply": "2025-12-23T20:38:28.737382Z",
     "shell.execute_reply.started": "2025-12-23T20:38:27.697099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+\n",
      "|id |date_iso   |date_dmy  |date_mdy  |timestamp          |parsed_date_iso|parsed_date_dmy|parsed_date_mdy|\n",
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+\n",
      "|1  |2023-01-15 |15/01/2023|01/15/2023|2023-01-15 10:30:00|2023-01-15     |2023-01-15     |2023-01-15     |\n",
      "|2  |2023-05-20 |20/05/2023|05/20/2023|2023-05-20 15:45:00|2023-05-20     |2023-05-20     |2023-05-20     |\n",
      "|3  |InvalidDate|31/02/2023|02/31/2023|InvalidTimestamp   |NULL           |NULL           |NULL           |\n",
      "|4  |NULL       |NULL      |NULL      |NULL               |NULL           |NULL           |NULL           |\n",
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8fcb44-e000-4684-ab35-fcd7a12b1b3e",
   "metadata": {},
   "source": [
    "# TimeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521f3fa0-26f7-415c-b798-6c45e054568d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:47:44.636962Z",
     "iopub.status.busy": "2025-12-23T20:47:44.636708Z",
     "iopub.status.idle": "2025-12-23T20:47:45.142610Z",
     "shell.execute_reply": "2025-12-23T20:47:45.142007Z",
     "shell.execute_reply.started": "2025-12-23T20:47:44.636943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n",
      "| id|   date_iso|  date_dmy|  date_mdy|          timestamp|parsed_date_iso|parsed_date_dmy|parsed_date_mdy|   parsed_timestamp|\n",
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n",
      "|  1| 2023-01-15|15/01/2023|01/15/2023|2023-01-15 10:30:00|     2023-01-15|     2023-01-15|     2023-01-15|2023-01-15 10:30:00|\n",
      "|  2| 2023-05-20|20/05/2023|05/20/2023|2023-05-20 15:45:00|     2023-05-20|     2023-05-20|     2023-05-20|2023-05-20 15:45:00|\n",
      "|  3|InvalidDate|31/02/2023|02/31/2023|   InvalidTimestamp|           NULL|           NULL|           NULL|               NULL|\n",
      "|  4|       NULL|      NULL|      NULL|               NULL|           NULL|           NULL|           NULL|               NULL|\n",
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- date_iso: string (nullable = true)\n",
      " |-- date_dmy: string (nullable = true)\n",
      " |-- date_mdy: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- parsed_date_iso: date (nullable = true)\n",
      " |-- parsed_date_dmy: date (nullable = true)\n",
      " |-- parsed_date_mdy: date (nullable = true)\n",
      " |-- parsed_timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp,year,month,dayofmonth,hour,minute\n",
    "\n",
    "df = df.withColumn('parsed_timestamp',to_timestamp(df.timestamp))\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611bb5ce-c270-47e1-80ec-2d91dd668320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:54:52.087935Z",
     "iopub.status.busy": "2025-12-23T20:54:52.087619Z",
     "iopub.status.idle": "2025-12-23T20:54:52.931138Z",
     "shell.execute_reply": "2025-12-23T20:54:52.930506Z",
     "shell.execute_reply.started": "2025-12-23T20:54:52.087901Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+----+-----+----+----+------+\n",
      "|id |date_iso   |date_dmy  |date_mdy  |timestamp          |parsed_date_iso|parsed_date_dmy|parsed_date_mdy|parsed_timestamp   |year|month|day |hour|minute|\n",
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+----+-----+----+----+------+\n",
      "|1  |2023-01-15 |15/01/2023|01/15/2023|2023-01-15 10:30:00|2023-01-15     |2023-01-15     |2023-01-15     |2023-01-15 10:30:00|2023|1    |15  |10  |30    |\n",
      "|2  |2023-05-20 |20/05/2023|05/20/2023|2023-05-20 15:45:00|2023-05-20     |2023-05-20     |2023-05-20     |2023-05-20 15:45:00|2023|5    |20  |15  |45    |\n",
      "|3  |InvalidDate|31/02/2023|02/31/2023|InvalidTimestamp   |NULL           |NULL           |NULL           |NULL               |NULL|NULL |NULL|NULL|NULL  |\n",
      "|4  |NULL       |NULL      |NULL      |NULL               |NULL           |NULL           |NULL           |NULL               |NULL|NULL |NULL|NULL|NULL  |\n",
      "+---+-----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+----+-----+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df\\\n",
    "        .withColumn('year',year(df.parsed_timestamp))\\\n",
    "        .withColumn('month',month(df.parsed_timestamp))\\\n",
    "        .withColumn('day',dayofmonth(df.parsed_timestamp))\\\n",
    "        .withColumn('hour',hour(df.parsed_timestamp))\\\n",
    "        .withColumn('minute',minute(df.parsed_timestamp))\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0336ac04-0e97-4721-a2da-f0444f6e920c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T20:58:19.082619Z",
     "iopub.status.busy": "2025-12-23T20:58:19.082366Z",
     "iopub.status.idle": "2025-12-23T20:58:19.792090Z",
     "shell.execute_reply": "2025-12-23T20:58:19.791340Z",
     "shell.execute_reply.started": "2025-12-23T20:58:19.082596Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+-----------+\n",
      "|parsed_date_mdy|parsed_date_iso|days_differ|\n",
      "+---------------+---------------+-----------+\n",
      "|2023-01-15     |2023-01-15     |0          |\n",
      "|2023-05-20     |2023-05-20     |0          |\n",
      "|NULL           |NULL           |NULL       |\n",
      "|NULL           |NULL           |NULL       |\n",
      "+---------------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff\n",
    "df = df.withColumn('days_differ',datediff(df.parsed_date_mdy,df.parsed_date_iso))\n",
    "df.select('parsed_date_mdy','parsed_date_iso','days_differ').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb028f42-d8f3-4afb-830c-78de13b3e149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T21:01:45.257418Z",
     "iopub.status.busy": "2025-12-23T21:01:45.256841Z",
     "iopub.status.idle": "2025-12-23T21:01:46.918400Z",
     "shell.execute_reply": "2025-12-23T21:01:46.917740Z",
     "shell.execute_reply.started": "2025-12-23T21:01:45.257397Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872f159-8610-4728-9b94-987e49cdf734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}